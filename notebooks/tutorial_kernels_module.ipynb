{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n",
        "# It can be customized to whatever you like\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training and evaluating quantum kernels\n",
        "=======================================\n",
        "\n",
        "::: {.meta}\n",
        ":property=\\\"og:description\\\": Kernels and alignment training with\n",
        "Pennylane. :property=\\\"og:image\\\":\n",
        "<https://pennylane.ai/qml/_images/QEK_thumbnail.png>\n",
        ":::\n",
        "\n",
        "::: {.related}\n",
        "tutorial\\_kernel\\_based\\_training Kernel-based training with\n",
        "scikit-learn tutorial\\_data\\_reuploading\\_classifier Classification with\n",
        "data reuploading\n",
        ":::\n",
        "\n",
        "*Authors: Peter-Jan Derks, Paul FÃ¤hrmann, Elies Gil-Fuster, Tom\n",
        "Hubregtsen, Johannes Jakob Meyer and David Wierichs. Posted: 24 June\n",
        "2021*\n",
        "\n",
        "Kernel methods are one of the cornerstones of classical machine\n",
        "learning. Here we are concerned with kernels that can be evaluated on\n",
        "quantum computers, *quantum kernels* for short. In this tutorial you\n",
        "will learn how to evaluate kernels, use them for classification and\n",
        "train them with gradient-based optimization, and all that using the\n",
        "functionality of PennyLane\\'s [kernels\n",
        "module](https://pennylane.readthedocs.io/en/latest/code/qml_kernels.html).\n",
        "The demo is based on Ref., a project from Xanadu\\'s own\n",
        "[QHack](https://qhack.ai/) hackathon.\n",
        "\n",
        "What are kernel methods?\n",
        "------------------------\n",
        "\n",
        "To understand what a kernel method does, let\\'s first revisit one of the\n",
        "simplest methods to assign binary labels to datapoints: linear\n",
        "classification.\n",
        "\n",
        "Imagine we want to discern two different classes of points that lie in\n",
        "different corners of the plane. A linear classifier corresponds to\n",
        "drawing a line and assigning different labels to the regions on opposing\n",
        "sides of the line:\n",
        "\n",
        "![](../demonstrations/kernels_module/linear_classification.png){.align-center\n",
        "width=\"30.0%\"}\n",
        "\n",
        "We can mathematically formalize this by assigning the label $y$ via\n",
        "\n",
        "$$y(\\boldsymbol{x}) = \\operatorname{sgn}(\\langle \\boldsymbol{w}, \\boldsymbol{x}\\rangle + b).$$\n",
        "\n",
        "The vector $\\boldsymbol{w}$ points perpendicular to the line and thus\n",
        "determine its slope. The independent term $b$ specifies the position on\n",
        "the plane. In this form, linear classification can also be extended to\n",
        "higher dimensional vectors $\\boldsymbol{x}$, where a line does not\n",
        "divide the entire space into two regions anymore. Instead one needs a\n",
        "*hyperplane*. It is immediately clear that this method is not very\n",
        "powerful, as datasets that are not separable by a hyperplane can\\'t be\n",
        "classified without error.\n",
        "\n",
        "We can actually sneak around this limitation by performing a neat trick:\n",
        "if we define some map $\\phi(\\boldsymbol{x})$ that *embeds* our\n",
        "datapoints into a larger *feature space* and then perform linear\n",
        "classification there, we could actually realise non-linear\n",
        "classification in our original space!\n",
        "\n",
        "![](../demonstrations/kernels_module/embedding_nonlinear_classification.png){.align-center\n",
        "width=\"65.0%\"}\n",
        "\n",
        "If we go back to the expression for our prediction and include the\n",
        "embedding, we get\n",
        "\n",
        "$$y(\\boldsymbol{x}) = \\operatorname{sgn}(\\langle \\boldsymbol{w}, \\phi(\\boldsymbol{x})\\rangle + b).$$\n",
        "\n",
        "We will forgo one tiny step, but it can be shown that for the purpose of\n",
        "optimal classification, we can choose the vector defining the decision\n",
        "boundary as a linear combination of the embedded datapoints\n",
        "$\\boldsymbol{w} = \\sum_i \\alpha_i \\phi(\\boldsymbol{x}_i)$. Putting this\n",
        "into the formula yields\n",
        "\n",
        "$$y(\\boldsymbol{x}) = \\operatorname{sgn}\\left(\\sum_i \\alpha_i \\langle \\phi(\\boldsymbol{x}_i), \\phi(\\boldsymbol{x})\\rangle + b\\right).$$\n",
        "\n",
        "This rewriting might not seem useful at first, but notice the above\n",
        "formula only contains inner products between vectors in the embedding\n",
        "space:\n",
        "\n",
        "$$k(\\boldsymbol{x}_i, \\boldsymbol{x}_j) = \\langle \\phi(\\boldsymbol{x}_i), \\phi(\\boldsymbol{x}_j)\\rangle.$$\n",
        "\n",
        "We call this function the *kernel*. It provides the advantage that we\n",
        "can often find an explicit formula for the kernel $k$ that makes it\n",
        "superfluous to actually perform the (potentially expensive) embedding\n",
        "$\\phi$. Consider for example the following embedding and the associated\n",
        "kernel:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "\\phi((x_1, x_2)) &= (x_1^2, \\sqrt{2} x_1 x_2, x_2^2) \\\\\n",
        "k(\\boldsymbol{x}, \\boldsymbol{y}) &= x_1^2 y_1^2 + 2 x_1 x_2 y_1 y_2 + x_2^2 y_2^2 = \\langle \\boldsymbol{x}, \\boldsymbol{y} \\rangle^2.\n",
        "\\end{aligned}$$\n",
        "\n",
        "This means by just replacing the regular scalar product in our linear\n",
        "classification with the map $k$, we can actually express much more\n",
        "intricate decision boundaries!\n",
        "\n",
        "This is very important, because in many interesting cases the embedding\n",
        "$\\phi$ will be much costlier to compute than the kernel $k$.\n",
        "\n",
        "In this demo, we will explore one particular kind of kernel that can be\n",
        "realized on near-term quantum computers, namely *Quantum Embedding\n",
        "Kernels (QEKs)*. These are kernels that arise from embedding data into\n",
        "the space of quantum states. We formalize this by considering a\n",
        "parameterised quantum circuit $U(\\boldsymbol{x})$ that maps a datapoint\n",
        "$\\boldsymbol{x}$ to the state\n",
        "\n",
        "$$|\\psi(\\boldsymbol{x})\\rangle = U(\\boldsymbol{x}) |0 \\rangle.$$\n",
        "\n",
        "The kernel value is then given by the *overlap* of the associated\n",
        "embedded quantum states\n",
        "\n",
        "$$k(\\boldsymbol{x}_i, \\boldsymbol{x}_j) = | \\langle\\psi(\\boldsymbol{x}_i)|\\psi(\\boldsymbol{x}_j)\\rangle|^2.$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A toy problem\n",
        "=============\n",
        "\n",
        "In this demo, we will treat a toy problem that showcases the inner\n",
        "workings of classification with quantum embedding kernels, training\n",
        "variational embedding kernels and the available functionalities to do\n",
        "both in PennyLane. We of course need to start with some imports:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pennylane import numpy as np\n",
        "import matplotlib as mpl\n",
        "\n",
        "np.random.seed(1359)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we proceed right away to create a dataset to work with, the\n",
        "`DoubleCake` dataset. Firstly, we define two functions to enable us to\n",
        "generate the data. The details of these functions are not essential for\n",
        "understanding the demo, so don\\'t mind them if they are confusing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _make_circular_data(num_sectors):\n",
        "    \"\"\"Generate datapoints arranged in an even circle.\"\"\"\n",
        "    center_indices = np.array(range(0, num_sectors))\n",
        "    sector_angle = 2 * np.pi / num_sectors\n",
        "    angles = (center_indices + 0.5) * sector_angle\n",
        "    x = 0.7 * np.cos(angles)\n",
        "    y = 0.7 * np.sin(angles)\n",
        "    labels = 2 * np.remainder(np.floor_divide(angles, sector_angle), 2) - 1\n",
        "\n",
        "    return x, y, labels\n",
        "\n",
        "\n",
        "def make_double_cake_data(num_sectors):\n",
        "    x1, y1, labels1 = _make_circular_data(num_sectors)\n",
        "    x2, y2, labels2 = _make_circular_data(num_sectors)\n",
        "\n",
        "    # x and y coordinates of the datapoints\n",
        "    x = np.hstack([x1, 0.5 * x2])\n",
        "    y = np.hstack([y1, 0.5 * y2])\n",
        "\n",
        "    # Canonical form of dataset\n",
        "    X = np.vstack([x, y]).T\n",
        "\n",
        "    labels = np.hstack([labels1, -1 * labels2])\n",
        "\n",
        "    # Canonical form of labels\n",
        "    Y = labels.astype(int)\n",
        "\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define a function to help plot the `DoubleCake` data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_double_cake_data(X, Y, ax, num_sectors=None):\n",
        "    \"\"\"Plot double cake data and corresponding sectors.\"\"\"\n",
        "    x, y = X.T\n",
        "    cmap = mpl.colors.ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
        "    ax.scatter(x, y, c=Y, cmap=cmap, s=25, marker=\"s\")\n",
        "\n",
        "    if num_sectors is not None:\n",
        "        sector_angle = 360 / num_sectors\n",
        "        for i in range(num_sectors):\n",
        "            color = [\"#FF0000\", \"#0000FF\"][(i % 2)]\n",
        "            other_color = [\"#FF0000\", \"#0000FF\"][((i + 1) % 2)]\n",
        "            ax.add_artist(\n",
        "                mpl.patches.Wedge(\n",
        "                    (0, 0),\n",
        "                    1,\n",
        "                    i * sector_angle,\n",
        "                    (i + 1) * sector_angle,\n",
        "                    lw=0,\n",
        "                    color=color,\n",
        "                    alpha=0.1,\n",
        "                    width=0.5,\n",
        "                )\n",
        "            )\n",
        "            ax.add_artist(\n",
        "                mpl.patches.Wedge(\n",
        "                    (0, 0),\n",
        "                    0.5,\n",
        "                    i * sector_angle,\n",
        "                    (i + 1) * sector_angle,\n",
        "                    lw=0,\n",
        "                    color=other_color,\n",
        "                    alpha=0.1,\n",
        "                )\n",
        "            )\n",
        "            ax.set_xlim(-1, 1)\n",
        "\n",
        "    ax.set_ylim(-1, 1)\n",
        "    ax.set_aspect(\"equal\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\\'s now have a look at our dataset. In our example, we will work with\n",
        "3 sectors:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_sectors = 3\n",
        "X, Y = make_double_cake_data(num_sectors)\n",
        "\n",
        "ax = plot_double_cake_data(X, Y, plt.gca(), num_sectors=num_sectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining a Quantum Embedding Kernel\n",
        "===================================\n",
        "\n",
        "PennyLane\\'s [kernels\n",
        "module](https://pennylane.readthedocs.io/en/latest/code/qml_kernels.html)\n",
        "allows for a particularly simple implementation of Quantum Embedding\n",
        "Kernels. The first ingredient we need for this is an *ansatz*, which we\n",
        "will construct by repeating a layer as building block. Let\\'s start by\n",
        "defining this layer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "\n",
        "\n",
        "def layer(x, params, wires, i0=0, inc=1):\n",
        "    \"\"\"Building block of the embedding ansatz\"\"\"\n",
        "    i = i0\n",
        "    for j, wire in enumerate(wires):\n",
        "        qml.Hadamard(wires=[wire])\n",
        "        qml.RZ(x[i % len(x)], wires=[wire])\n",
        "        i += inc\n",
        "        qml.RY(params[0, j], wires=[wire])\n",
        "\n",
        "    qml.broadcast(unitary=qml.CRZ, pattern=\"ring\", wires=wires, parameters=params[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To construct the ansatz, this layer is repeated multiple times, reusing\n",
        "the datapoint `x` but feeding different variational parameters `params`\n",
        "into each of them. Together, the datapoint and the variational\n",
        "parameters fully determine the embedding ansatz $U(\\boldsymbol{x})$. In\n",
        "order to construct the full kernel circuit, we also require its adjoint\n",
        "$U(\\boldsymbol{x})^\\dagger$, which we can obtain via `qml.adjoint`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def ansatz(x, params, wires):\n",
        "    \"\"\"The embedding ansatz\"\"\"\n",
        "    for j, layer_params in enumerate(params):\n",
        "        layer(x, layer_params, wires, i0=j * len(wires))\n",
        "\n",
        "\n",
        "adjoint_ansatz = qml.adjoint(ansatz)\n",
        "\n",
        "\n",
        "def random_params(num_wires, num_layers):\n",
        "    \"\"\"Generate random variational parameters in the shape for the ansatz.\"\"\"\n",
        "    return np.random.uniform(0, 2 * np.pi, (num_layers, 2, num_wires), requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Together with the ansatz we only need a device to run the quantum\n",
        "circuit on. For the purpose of this tutorial we will use PennyLane\\'s\n",
        "`default.qubit` device with 5 wires in analytic mode.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit\", wires=5, shots=None)\n",
        "wires = dev.wires.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now define the quantum circuit that realizes the kernel. We will\n",
        "compute the overlap of the quantum states by first applying the\n",
        "embedding of the first datapoint and then the adjoint of the embedding\n",
        "of the second datapoint. We finally extract the probabilities of\n",
        "observing each basis state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev)\n",
        "def kernel_circuit(x1, x2, params):\n",
        "    ansatz(x1, params, wires=wires)\n",
        "    adjoint_ansatz(x2, params, wires=wires)\n",
        "    return qml.probs(wires=wires)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The kernel function itself is now obtained by looking at the probability\n",
        "of observing the all-zero state at the end of the kernel circuit \\--\n",
        "because of the ordering in `qml.probs`, this is the first entry:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def kernel(x1, x2, params):\n",
        "    return kernel_circuit(x1, x2, params)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.note}\n",
        "::: {.admonition-title}\n",
        "Note\n",
        ":::\n",
        "\n",
        "An alternative way to set up the kernel circuit in PennyLane would be to\n",
        "use the observable type\n",
        "[Projector](https://pennylane.readthedocs.io/en/latest/code/api/pennylane.Projector.html).\n",
        "This is shown in the [demo on kernel-based training of quantum\n",
        "models](https://pennylane.ai/qml/demos/tutorial_kernel_based_training.html),\n",
        "where you will also find more background information on the kernel\n",
        "circuit structure itself.\n",
        ":::\n",
        "\n",
        "Before focusing on the kernel values we have to provide values for the\n",
        "variational parameters. At this point we fix the number of layers in the\n",
        "ansatz circuit to $6$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "init_params = random_params(num_wires=5, num_layers=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can have a look at the kernel value between the first and the\n",
        "second datapoint:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The kernel value between the first and second datapoint is 0.093\n"
          ]
        }
      ],
      "source": [
        "kernel_value = kernel(X[0], X[1], init_params)\n",
        "print(f\"The kernel value between the first and second datapoint is {kernel_value:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 3.50000000e-01  6.06217783e-01]\n",
            " [-7.00000000e-01  8.57252759e-17]\n",
            " [ 3.50000000e-01 -6.06217783e-01]\n",
            " [ 1.75000000e-01  3.03108891e-01]\n",
            " [-3.50000000e-01  4.28626380e-17]\n",
            " [ 1.75000000e-01 -3.03108891e-01]]\n",
            "[-1  1 -1  1 -1  1]\n"
          ]
        }
      ],
      "source": [
        "print(X)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mutual kernel values between all elements of the dataset form the\n",
        "*kernel matrix*. We can inspect it via the\n",
        "`qml.kernels.square_kernel_matrix` method, which makes use of symmetry\n",
        "of the kernel,\n",
        "$k(\\boldsymbol{x}_i,\\boldsymbol{x}_j) = k(\\boldsymbol{x}_j, \\boldsymbol{x}_i)$.\n",
        "In addition, the option `assume_normalized_kernel=True` ensures that we\n",
        "do not calculate the entries between the same datapoints, as we know\n",
        "them to be 1 for our noiseless simulation. Overall this means that we\n",
        "compute $\\frac{1}{2}(N^2-N)$ kernel values for $N$ datapoints. To\n",
        "include the variational parameters, we construct a `lambda` function\n",
        "that fixes them to the values we sampled above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.    0.093 0.012 0.721 0.149 0.055]\n",
            " [0.093 1.    0.056 0.218 0.73  0.213]\n",
            " [0.012 0.056 1.    0.032 0.191 0.648]\n",
            " [0.721 0.218 0.032 1.    0.391 0.226]\n",
            " [0.149 0.73  0.191 0.391 1.    0.509]\n",
            " [0.055 0.213 0.648 0.226 0.509 1.   ]]\n"
          ]
        }
      ],
      "source": [
        "init_kernel = lambda x1, x2: kernel(x1, x2, init_params)\n",
        "K_init = qml.kernels.square_kernel_matrix(X, init_kernel, assume_normalized_kernel=True)\n",
        "\n",
        "with np.printoptions(precision=3, suppress=True):\n",
        "    print(K_init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the Quantum Embedding Kernel for predictions\n",
        "==================================================\n",
        "\n",
        "The quantum kernel alone can not be used to make predictions on a\n",
        "dataset, becaues it is essentially just a tool to measure the similarity\n",
        "between two datapoints. To perform an actual prediction we will make use\n",
        "of scikit-learn\\'s Support Vector Classifier (SVC).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To construct the SVM, we need to supply `sklearn.svm.SVC` with a\n",
        "function that takes two sets of datapoints and returns the associated\n",
        "kernel matrix. We can make use of the function\n",
        "`qml.kernels.kernel_matrix` that provides this functionality. It expects\n",
        "the kernel to not have additional parameters besides the datapoints,\n",
        "which is why we again supply the variational parameters via the `lambda`\n",
        "function from above. Once we have this, we can let scikit-learn adjust\n",
        "the SVM from our Quantum Embedding Kernel.\n",
        "\n",
        "::: {.note}\n",
        "::: {.admonition-title}\n",
        "Note\n",
        ":::\n",
        "\n",
        "This step does *not* modify the variational parameters in our circuit\n",
        "ansatz. What it does is solving a different optimization task for the\n",
        "$\\alpha$ and $b$ vectors we introduced in the beginning.\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "svm = SVC(kernel=lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, init_kernel)).fit(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see how well our classifier performs we will measure which percentage\n",
        "of the dataset it classifies correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of the kernel with random parameters is 0.833\n"
          ]
        }
      ],
      "source": [
        "def accuracy(classifier, X, Y_target):\n",
        "    return 1 - np.count_nonzero(classifier.predict(X) - Y_target) / len(Y_target)\n",
        "\n",
        "\n",
        "accuracy_init = accuracy(svm, X, Y)\n",
        "print(f\"The accuracy of the kernel with random parameters is {accuracy_init:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are also interested in seeing what the decision boundaries in this\n",
        "classification look like. This could help us spotting overfitting issues\n",
        "visually in more complex data sets. To this end we will introduce a\n",
        "second helper method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundaries(classifier, ax, N_gridpoints=14):\n",
        "    _xx, _yy = np.meshgrid(np.linspace(-1, 1, N_gridpoints), np.linspace(-1, 1, N_gridpoints))\n",
        "\n",
        "    _zz = np.zeros_like(_xx)\n",
        "    for idx in np.ndindex(*_xx.shape):\n",
        "        _zz[idx] = classifier.predict(np.array([_xx[idx], _yy[idx]])[np.newaxis, :])\n",
        "\n",
        "    plot_data = {\"_xx\": _xx, \"_yy\": _yy, \"_zz\": _zz}\n",
        "    ax.contourf(\n",
        "        _xx,\n",
        "        _yy,\n",
        "        _zz,\n",
        "        cmap=mpl.colors.ListedColormap([\"#FF0000\", \"#0000FF\"]),\n",
        "        alpha=0.2,\n",
        "        levels=[-1, 0, 1],\n",
        "    )\n",
        "    plot_double_cake_data(X, Y, ax)\n",
        "\n",
        "    return plot_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With that done, let\\'s have a look at the decision boundaries for our\n",
        "initial classifier:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "init_plot_data = plot_decision_boundaries(svm, plt.gca())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see the outer points in the dataset can be correctly classified, but\n",
        "we still struggle with the inner circle. But remember we have a circuit\n",
        "with many free parameters! It is reasonable to believe we can give\n",
        "values to those variational parameters which improve the overall\n",
        "accuracy of our SVC.\n",
        "\n",
        "Training the Quantum Embedding Kernel\n",
        "=====================================\n",
        "\n",
        "To be able to train the Quantum Embedding Kernel we need some measure of\n",
        "how well it fits the dataset in question. Performing an exhaustive\n",
        "search in parameter space is not a good solution because it is very\n",
        "resource intensive, and since the accuracy is a discrete quantity we\n",
        "would not be able to detect small improvements.\n",
        "\n",
        "We can, however, resort to a more specialized measure, the\n",
        "*kernel-target alignment*. The kernel-target alignment compares the\n",
        "similarity predicted by the quantum kernel to the actual labels of the\n",
        "training data. It is based on *kernel alignment*, a similiarity measure\n",
        "between two kernels with given kernel matrices $K_1$ and $K_2$:\n",
        "\n",
        "$$\\operatorname{KA}(K_1, K_2) = \\frac{\\operatorname{Tr}(K_1 K_2)}{\\sqrt{\\operatorname{Tr}(K_1^2)\\operatorname{Tr}(K_2^2)}}.$$\n",
        "\n",
        "::: {.note}\n",
        "::: {.admonition-title}\n",
        "Note\n",
        ":::\n",
        "\n",
        "Seen from a more theoretical side, $\\operatorname{KA}$ is nothing else\n",
        "than the cosine of the angle between the kernel matrices $K_1$ and $K_2$\n",
        "if we see them as vectors in the space of matrices with the\n",
        "Hilbert-Schmidt (or Frobenius) scalar product\n",
        "$\\langle A, B \\rangle = \\operatorname{Tr}(A^T B)$. This reinforces the\n",
        "geometric picture of how this measure relates to objects, namely two\n",
        "kernels, being aligned in a vector space.\n",
        ":::\n",
        "\n",
        "The training data enters the picture by defining an *ideal* kernel\n",
        "function that expresses the original labelling in the vector\n",
        "$\\boldsymbol{y}$ by assigning to two datapoints the product of the\n",
        "corresponding labels:\n",
        "\n",
        "$$k_{\\boldsymbol{y}}(\\boldsymbol{x}_i, \\boldsymbol{x}_j) = y_i y_j.$$\n",
        "\n",
        "The assigned kernel is thus $+1$ if both datapoints lie in the same\n",
        "class and $-1$ otherwise and its kernel matrix is simply given by the\n",
        "outer product $\\boldsymbol{y}\\boldsymbol{y}^T$. The kernel-target\n",
        "alignment is then defined as the kernel alignment of the kernel matrix\n",
        "$K$ generated by the quantum kernel and\n",
        "$\\boldsymbol{y}\\boldsymbol{y}^T$:\n",
        "\n",
        "$$\\operatorname{KTA}_{\\boldsymbol{y}}(K)\n",
        "= \\frac{\\operatorname{Tr}(K \\boldsymbol{y}\\boldsymbol{y}^T)}{\\sqrt{\\operatorname{Tr}(K^2)\\operatorname{Tr}((\\boldsymbol{y}\\boldsymbol{y}^T)^2)}}\n",
        "= \\frac{\\boldsymbol{y}^T K \\boldsymbol{y}}{\\sqrt{\\operatorname{Tr}(K^2)} N}$$\n",
        "\n",
        "where $N$ is the number of elements in $\\boldsymbol{y}$, that is the\n",
        "number of datapoints in the dataset.\n",
        "\n",
        "In summary, the kernel-target alignment effectively captures how well\n",
        "the kernel you chose reproduces the actual similarities of the data. It\n",
        "does have one drawback, however: having a high kernel-target alignment\n",
        "is only a necessary but not a sufficient condition for a good\n",
        "performance of the kernel. This means having good alignment is\n",
        "guaranteed for good performance, but optimal alignment will not always\n",
        "bring optimal training accuracy with it.\n",
        "\n",
        "Let\\'s now come back to the actual implementation. PennyLane\\'s\n",
        "`kernels` module allows you to easily evaluate the kernel target\n",
        "alignment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The kernel-target alignment for our dataset and random parameters is 0.081\n"
          ]
        }
      ],
      "source": [
        "kta_init = qml.kernels.target_alignment(X, Y, init_kernel, assume_normalized_kernel=True)\n",
        "\n",
        "print(f\"The kernel-target alignment for our dataset and random parameters is {kta_init:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let\\'s code up an optimization loop and improve the kernel-target\n",
        "alignment!\n",
        "\n",
        "We will make use of regular gradient descent optimization. To speed up\n",
        "the optimization we will not use the entire training set to compute\n",
        "$\\operatorname{KTA}$ but rather sample smaller subsets of the data at\n",
        "each step, we choose $4$ datapoints at random. Remember that\n",
        "PennyLane\\'s built-in optimizer works to *minimize* the cost function\n",
        "that is given to it, which is why we have to multiply the kernel target\n",
        "alignment by $-1$ to actually *maximize* it in the process.\n",
        "\n",
        "::: {.note}\n",
        "::: {.admonition-title}\n",
        "Note\n",
        ":::\n",
        "\n",
        "Currently, the function `qml.kernels.target_alignment` is not\n",
        "differentiable yet, making it unfit for gradient descent optimization.\n",
        "We therefore first define a differentiable version of this function.\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "Step 50 - Alignment = 0.097\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n",
            "(6, 2, 5)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/anani/Code/master-thesis/code/notebooks/tutorial_kernels_module.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anani/Code/master-thesis/code/notebooks/tutorial_kernels_module.ipynb#X54sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# Optimization step\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anani/Code/master-thesis/code/notebooks/tutorial_kernels_module.ipynb#X54sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mprint\u001b[39m(params\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anani/Code/master-thesis/code/notebooks/tutorial_kernels_module.ipynb#X54sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m params \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39;49mstep(cost, params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anani/Code/master-thesis/code/notebooks/tutorial_kernels_module.ipynb#X54sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Report the alignment on the full dataset every 50 steps.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anani/Code/master-thesis/code/notebooks/tutorial_kernels_module.ipynb#X54sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:88\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step\u001b[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, objective_fn, \u001b[39m*\u001b[39margs, grad_fn\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     71\u001b[0m     \u001b[39m\"\"\"Update trainable arguments with one step of the optimizer.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     g, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_grad(objective_fn, args, kwargs, grad_fn\u001b[39m=\u001b[39;49mgrad_fn)\n\u001b[1;32m     89\u001b[0m     new_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_grad(g, args)\n\u001b[1;32m     91\u001b[0m     \u001b[39m# unwrap from list if one argument, cleaner return\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py:117\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[0;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m g \u001b[39m=\u001b[39m get_gradient(objective_fn) \u001b[39mif\u001b[39;00m grad_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m grad_fn\n\u001b[0;32m--> 117\u001b[0m grad \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m forward \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(g, \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m num_trainable_args \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mgetattr\u001b[39m(arg, \u001b[39m\"\u001b[39m\u001b[39mrequires_grad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/pennylane/_grad.py:115\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m ()\n\u001b[0;32m--> 115\u001b[0m grad_value, ans \u001b[39m=\u001b[39m grad_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward \u001b[39m=\u001b[39m ans\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m grad_value\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(args[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[39mreturn\u001b[39;00m unary_operator(unary_f, x, \u001b[39m*\u001b[39;49mnary_op_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnary_op_kwargs)\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/pennylane/_grad.py:141\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vspace(ans)\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    136\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    137\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGrad only applies to real scalar-output functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[0;32m--> 141\u001b[0m grad_value \u001b[39m=\u001b[39m vjp(vspace(ans)\u001b[39m.\u001b[39;49mones())\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m grad_value, ans\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/autograd/core.py:14\u001b[0m, in \u001b[0;36mmake_vjp.<locals>.vjp\u001b[0;34m(g)\u001b[0m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvjp\u001b[39m(g): \u001b[39mreturn\u001b[39;00m backward_pass(g, end_node)\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/autograd/core.py:22\u001b[0m, in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     20\u001b[0m     outgrad \u001b[39m=\u001b[39m outgrads\u001b[39m.\u001b[39mpop(node)\n\u001b[1;32m     21\u001b[0m     ingrads \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvjp(outgrad[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mfor\u001b[39;00m parent, ingrad \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(node\u001b[39m.\u001b[39mparents, ingrads):\n\u001b[1;32m     23\u001b[0m         outgrads[parent] \u001b[39m=\u001b[39m add_outgrads(outgrads\u001b[39m.\u001b[39mget(parent), ingrad)\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m outgrad[\u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/autograd/core.py:49\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvjp_argnums\u001b[39m(argnums, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     48\u001b[0m     vjps \u001b[39m=\u001b[39m [vjpmaker(argnum, \u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m argnum \u001b[39min\u001b[39;00m argnums]\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m g: (vjp(g) \u001b[39mfor\u001b[39;00m vjp \u001b[39min\u001b[39;00m vjps)\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/autograd/numpy/numpy_vjps.py:619\u001b[0m, in \u001b[0;36mgrad_einsum.<locals>.vjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    616\u001b[0m         new_operands \u001b[39m=\u001b[39m (g,) \u001b[39m+\u001b[39m rest_of_ops\n\u001b[1;32m    618\u001b[0m     new_subscripts \u001b[39m=\u001b[39m new_input_subs \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m->\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m subs_wrt\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m unbroadcast(anp\u001b[39m.\u001b[39;49meinsum(new_subscripts, \u001b[39m*\u001b[39;49mnew_operands), result_meta)\n\u001b[1;32m    620\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# using (op0, sublist0, op1, sublist1, ..., sublistout) convention\u001b[39;00m\n\u001b[1;32m    621\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(operands) \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m f_raw(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[0;32m~/miniforge3/envs/qc4rs/lib/python3.9/site-packages/numpy/core/einsumfunc.py:1359\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[39mif\u001b[39;00m specified_out:\n\u001b[1;32m   1358\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m out\n\u001b[0;32m-> 1359\u001b[0m     \u001b[39mreturn\u001b[39;00m c_einsum(\u001b[39m*\u001b[39;49moperands, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1361\u001b[0m \u001b[39m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m \u001b[39m# repeat default values here\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m valid_einsum_kwargs \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morder\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcasting\u001b[39m\u001b[39m'\u001b[39m]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def target_alignment(\n",
        "    X,\n",
        "    Y,\n",
        "    kernel,\n",
        "    assume_normalized_kernel=False,\n",
        "    rescale_class_labels=True,\n",
        "):\n",
        "    \"\"\"Kernel-target alignment between kernel and labels.\"\"\"\n",
        "\n",
        "    K = qml.kernels.square_kernel_matrix(\n",
        "        X,\n",
        "        kernel,\n",
        "        assume_normalized_kernel=assume_normalized_kernel,\n",
        "    )\n",
        "\n",
        "    if rescale_class_labels:\n",
        "        nplus = np.count_nonzero(np.array(Y) == 1)\n",
        "        nminus = len(Y) - nplus\n",
        "        _Y = np.array([y / nplus if y == 1 else y / nminus for y in Y])\n",
        "    else:\n",
        "        _Y = np.array(Y)\n",
        "\n",
        "    T = np.outer(_Y, _Y)\n",
        "    inner_product = np.sum(K * T)\n",
        "    norm = np.sqrt(np.sum(K * K) * np.sum(T * T))\n",
        "    inner_product = inner_product / norm\n",
        "\n",
        "    return inner_product\n",
        "\n",
        "\n",
        "params = init_params\n",
        "opt = qml.GradientDescentOptimizer(0.2)\n",
        "\n",
        "for i in range(500):\n",
        "    # Choose subset of datapoints to compute the KTA on.\n",
        "    subset = np.random.choice(list(range(len(X))), 4)\n",
        "    # Define the cost function for optimization\n",
        "    cost = lambda _params: -target_alignment(\n",
        "        X[subset],\n",
        "        Y[subset],\n",
        "        lambda x1, x2: kernel(x1, x2, _params),\n",
        "        assume_normalized_kernel=True,\n",
        "    )\n",
        "    # Optimization step\n",
        "    print(params.shape)\n",
        "    params = opt.step(cost, params)\n",
        "\n",
        "    # Report the alignment on the full dataset every 50 steps.\n",
        "    if (i + 1) % 50 == 0:\n",
        "        current_alignment = target_alignment(\n",
        "            X,\n",
        "            Y,\n",
        "            lambda x1, x2: kernel(x1, x2, params),\n",
        "            assume_normalized_kernel=True,\n",
        "        )\n",
        "        print(f\"Step {i+1} - Alignment = {current_alignment:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to assess the impact of training the parameters of the quantum\n",
        "kernel. Thus, let\\'s build a second support vector classifier with the\n",
        "trained kernel:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First create a kernel with the trained parameter baked into it.\n",
        "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
        "\n",
        "# Second create a kernel matrix function using the trained kernel.\n",
        "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
        "\n",
        "# Note that SVC expects the kernel argument to be a kernel matrix function.\n",
        "svm_trained = SVC(kernel=trained_kernel_matrix).fit(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We expect to see an accuracy improvement vs.Â the SVM with random\n",
        "parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of a kernel with trained parameters is 1.000\n"
          ]
        }
      ],
      "source": [
        "accuracy_trained = accuracy(svm_trained, X, Y)\n",
        "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have now achieved perfect classification! ð\n",
        "\n",
        "Following on the results that SVM\\'s have proven good generalisation\n",
        "behavior, it will be interesting to inspect the decision boundaries of\n",
        "our classifier:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "trained_plot_data = plot_decision_boundaries(svm_trained, plt.gca())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Indeed, we see that now not only every data instance falls within the\n",
        "correct class, but also that there are no strong artifacts that would\n",
        "make us distrust the model. In this sense, our approach benefits from\n",
        "both: on one hand it can adjust itself to the dataset, and on the other\n",
        "hand is not expected to suffer from bad generalisation.\n",
        "\n",
        "References\n",
        "==========\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('qc4rs')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "058c412d2185494a0ef6a033638010b3d9d5f5e8ee51f2c4e44f0472f9f04685"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
